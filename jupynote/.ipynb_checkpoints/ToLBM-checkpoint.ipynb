{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bbcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps: 1.Data generation 2.Collision Constructor 3. Dataset Building 4. \n",
    "# A function for use to generate data and validate it in four steps \n",
    "# (1) Naive Method -> just satisfy masss conservation continiuity eq. [This model is computationaly expensive and doesn't guarantee physical constraints]\n",
    "# (2) Satisfying symmetric condition byenforcing \\phi_NN be equivarience in respect to D_8 using group averaging [This method doesn't satisfy Postulate 3 mass & moment invarient cond.]\n",
    "# (3) Conservation of both Mass and Monmentum in x and y dir in which we need to use Algebraic fix: [This method does't satisfy Postulate 2 equivariance cond.]\n",
    "# (3.1) Algebraic Reconstruction (Biased for rows 2, 5, & 8). Why?\n",
    "# (3.2) Symmetric Algebraic Reconstruction with group-averaging method\n",
    "# (3.3) Penalize mass and momentum mismatches with a soft constraint in the loss function\n",
    "# Combined Symmetric-Conservation to satisfy all 4 Postulates at once and be computationally efficient by reducing degrees of freedom for D2Q9 from 90 down to 18\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate_training_data_bgk(\n",
    "    N_samples=1200000,\n",
    "    rho_min=0.5, rho_max=2.0,\n",
    "    u_max=0.03,\n",
    "    tau=1.0,\n",
    "    c_s=1.0/np.sqrt(3.0)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates (f_pre, f_post)(N_samples, 9) for the D2Q9 BGK model by:\n",
    "    We sample macro values for density & velocity for our training data to use in NN, by using f_eq.i and\n",
    "    then adding perturbation to that. Finally we calculate BGK post collision for f_post.i ...\n",
    "    \"\"\"\n",
    "    # D2Q9 discrete velocities\n",
    "    V_d = np.array([\n",
    "        [ 0,  0],\n",
    "        [ 1,  0],\n",
    "        [ 0,  1],\n",
    "        [-1,  0],\n",
    "        [ 0, -1],\n",
    "        [ 1,  1],\n",
    "        [-1,  1],\n",
    "        [-1, -1],\n",
    "        [ 1, -1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    # Standard D2Q9 weights\n",
    "    w = np.array([4/9, 1/9, 1/9, 1/9, 1/9, 1/36, 1/36, 1/36, 1/36], dtype=np.float64)\n",
    "\n",
    "    f_pre_list, f_post_list = [], []  # Generate list to append later\n",
    "\n",
    "    for _ in range(N_samples):\n",
    "        # # Alocating random density & velocity\n",
    "        rho, speed, angle = np.random.uniform([rho_min, 0.0, 0.0], [rho_max, u_max, 2*np.pi])\n",
    "        ux = speed * np.cos(angle)\n",
    "        uy = speed * np.sin(angle)\n",
    "\n",
    "        # ## Compute f_eq.i with 2_nd order Hermite expansion\n",
    "        f_eq = np.zeros(9, dtype=np.float64)\n",
    "        for i in range(9):\n",
    "            cu = V_d[i,0]*ux + V_d[i,1]*uy\n",
    "            f_eq[i] = w[i] * rho * (\n",
    "                1.0 + (cu)/(c_s**2) + 0.5*((cu)/(c_s**2))**2 - 0.5*( (ux**2 + uy**2)/(c_s**2) )\n",
    "            )\n",
    "\n",
    "        # ### Generate perturbation fneq with mass & momentum sum==0\n",
    "        \n",
    "        ## -------------\n",
    "        ## -- Phase 1 --\n",
    "        ## -------------\n",
    "        raw_perturb = np.random.normal(loc=0.0, scale=0.001, size=9)\n",
    "        \n",
    "        # -- Mass Conservation --\n",
    "        raw_perturb -= np.mean(raw_perturb) # shifts all perturbations by the average to satisfy continuity\n",
    "\n",
    "        # The folowing is commented for use in more advanced method which needs improvement  (to be complited)\n",
    "        \"\"\" \n",
    "        # -- Momentum Conservation --\n",
    "        vx_all = velocities[:,0]  # array of shape (9,)\n",
    "        vy_all = velocities[:,1]  \n",
    "\n",
    "        # Current net momentum in x, y due to raw_perturb:\n",
    "        dx = np.sum(raw_perturb * vx_all)\n",
    "        dy = np.sum(raw_perturb * vy_all)\n",
    "\n",
    "        # Build the 2x2 matrix for the linear system:\n",
    "        # [A11 A12] [alpha] = [dx]\n",
    "        # [A21 A22] [beta ]   [dy]\n",
    "        # where alpha, beta are how much to project out\n",
    "        A11 = np.sum(vx_all * vx_all)\n",
    "        A12 = np.sum(vx_all * vy_all)\n",
    "        A21 = A12\n",
    "        A22 = np.sum(vy_all * vy_all)\n",
    "\n",
    "        # Solve for alpha, beta\n",
    "        #   [alpha, beta]^T = inv(A) * [dx, dy]^T\n",
    "        # A = [[A11, A12],[A21,A22]]\n",
    "        # b = [dx, dy]\n",
    "        detA = A11*A22 - A12*A21\n",
    "        if abs(detA) > 1e-14:\n",
    "            alpha = ( A22*dx - A12*dy ) / detA\n",
    "            beta  = (-A21*dx + A11*dy ) / detA\n",
    "        else:\n",
    "            # fallback if degenerate; usually won't happen in D2Q9\n",
    "            alpha, beta = 0.0, 0.0\n",
    "\n",
    "        # Subtract alpha*vx + beta*vy from raw_perturb\n",
    "        raw_perturb -= alpha*vx_all + beta*vy_all\n",
    "        \n",
    "        ## -------------\n",
    "        ## -- Phase 2 --\n",
    "        ## -------------\n",
    "\n",
    "        # (C) Zero net mass again\n",
    "        raw_perturb -= np.mean(raw_perturb)\n",
    "\n",
    "        # (D) Zero net momentum in x,y again\n",
    "        dx2 = np.sum(raw_perturb * vx_all)\n",
    "        dy2 = np.sum(raw_perturb * vy_all)\n",
    "\n",
    "        if abs(detA) > 1e-14:\n",
    "            alpha2 = (A22 * dx2 - A12 * dy2) / detA\n",
    "            beta2  = (-A21 * dx2 + A11 * dy2) / detA\n",
    "        else:\n",
    "            alpha2, beta2 = 0.0, 0.0\n",
    "\n",
    "        raw_perturb -= alpha2 * vx_all + beta2 * vy_all\n",
    "        \"\"\"\n",
    "        \n",
    "        f_pre = f_eq + raw_perturb\n",
    "\n",
    "        # #### Compute BGK\n",
    "        f_post = f_pre - (1.0/tau)*(f_pre - f_eq)\n",
    "\n",
    "        f_pre_list.append(f_pre)\n",
    "        f_post_list.append(f_post)\n",
    "\n",
    "    f_pre_array = np.array(f_pre_list)\n",
    "    f_post_array = np.array(f_post_list)\n",
    "\n",
    "    return f_pre_array, f_post_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2963b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deo/Programms/MLBM/mlenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cba8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# Constructor for handling layers for each collision\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NaiveCollision(nn.Module): \n",
    "    def __init__(self, hidden_size=50):\n",
    "        super().__init__()\n",
    "        # Naive simple 9->hidden->hidden->9 layer definition\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(9, hidden_size, bias=False),\n",
    "            nn.ReLU(), # Hidden Layer activation\n",
    "            nn.Linear(hidden_size, hidden_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 9, bias=False)  # final: 9 outputs\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74fdb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MSRE loss function\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "class MSRELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super(MSRELoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        relative_error = (input - target) / (target + self.eps)\n",
    "        return torch.mean(relative_error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439298e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to build a dataset and train it \n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_naive(f_pre, f_post, \n",
    "                    epochs=200, batch_size=32, lr=1e-3,  # learning rate in W := W - lr * dL/dw\n",
    "                    hidden_size=50, device='cpu'):\n",
    "    \"\"\"\n",
    "    f_pre, f_post: NumPy arrays, shape (N,9).\n",
    "    We'll do naive MLP training for mapping f_pre->f_post.\n",
    "    returns trained model\n",
    "    \"\"\"\n",
    "    X = torch.from_numpy(f_pre).float().to(device)\n",
    "    Y = torch.from_numpy(f_post).float().to(device)\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # Does the splitting, shuffling, and iterate \n",
    "    \n",
    "    # Create Network + Optimizer + Loss Function\n",
    "    network = NaiveCollision(hidden_size=hidden_size).to(device) # we have created the network on device named netwrok\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr) \n",
    "    lossFunction = MSRELoss()\n",
    "    \n",
    "    # Main loop\n",
    "    network.train() # This put the network in training mode\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0.0 # What we want (Our Goal)\n",
    "        for batch_x, batch_y in dataloader: # batch_x == (batch_size, 9)\n",
    "            \n",
    "            optimizer.zero_grad() # Reset .gard from the past loop (forward -> backward -> update)\n",
    "            \n",
    "            pred_y = network(batch_x) # Compute the predicted y from x fed to the network on a chosen device\n",
    "            loss = lossFunction(pred_y, batch_y) # MSRE\n",
    "            \n",
    "            loss.backward() # W := W - lr * dL/dw\n",
    "            optimizer.step() # Update the weights\n",
    "            total_loss += loss.item()*batch_x.size(0) # We get the float from loss * batch size \n",
    "            \n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        if (ep+1)%10==0:\n",
    "            print(f\"Epoch {ep+1}/{epochs}, Loss={avg_loss:.6f}\")\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a026f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'MSRELoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest MSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m==\u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mmain_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain_naive\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m f_pre_test, f_post_test = generate_training_data_bgk(N_samples=\u001b[32m200000\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model = \u001b[43mtrain_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_pre_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_post_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Evaluate on test\u001b[39;00m\n\u001b[32m     17\u001b[39m model.eval()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_naive\u001b[39m\u001b[34m(f_pre, f_post, epochs, batch_size, lr, hidden_size, device)\u001b[39m\n\u001b[32m     19\u001b[39m network = NaiveCollision(hidden_size=hidden_size).to(device) \u001b[38;5;66;03m# we have created the network on device named netwrok\u001b[39;00m\n\u001b[32m     20\u001b[39m optimizer = optim.Adam(network.parameters(), lr=lr) \n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m lossFunction = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMSRELoss\u001b[49m()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[32m     24\u001b[39m network.train() \u001b[38;5;66;03m# This put the network in training mode\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch.nn' has no attribute 'MSRELoss'"
     ]
    }
   ],
   "source": [
    "def main_naive():\n",
    "    import torch\n",
    "    \n",
    "    # Generate\n",
    "    f_pre_train, f_post_train = generate_training_data_bgk(N_samples=1000000)\n",
    "    f_pre_test, f_post_test = generate_training_data_bgk(N_samples=200000)\n",
    "    \n",
    "    # Train\n",
    "    model = train_naive(f_pre_train, f_post_train,\n",
    "                            epochs=200, \n",
    "                            batch_size=32,\n",
    "                            lr=1e-3,\n",
    "                            hidden_size=50,\n",
    "                            device=\"cpu\")\n",
    "    \n",
    "    # Evaluate on test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_t = torch.from_numpy(f_pre_test).float().to(device)\n",
    "        y_true = torch.from_numpy(f_post_test).float().to(device)\n",
    "        y_pred = model(x_t)\n",
    "        mse_test = torch.mean((y_pred - y_true)**2).item()\n",
    "    print(f\"Test MSE = {mse_test:.6e}\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main_naive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043893e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
